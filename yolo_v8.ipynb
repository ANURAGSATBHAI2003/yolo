{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"10PJ4JZ5_poyghiegJFawybGjHfCOXctd","authorship_tag":"ABX9TyMwtP8TPiVgMuSgbA3T8zyZ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"ccac1a1d4fa94d6884d008f891cc1fec":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9d59f586961c43fc848940dd906dbc4c","IPY_MODEL_04e785dc9ccc470bb8e6ad077305ab9f","IPY_MODEL_2daa98354c5f41d490e6b217d0b5df15"],"layout":"IPY_MODEL_628937f54b934e00b568bc8acfc947b4"}},"9d59f586961c43fc848940dd906dbc4c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_730153ebc5ce4bf7b709ccdd7f6b67e8","placeholder":"​","style":"IPY_MODEL_4cdfb5834ee543658da77a1c8c015256","value":"100%"}},"04e785dc9ccc470bb8e6ad077305ab9f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4820da4c61d3402fb4487bc3f10fea55","max":53,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ba59a934aa1d4bbfb60a644d7c8fb7e3","value":53}},"2daa98354c5f41d490e6b217d0b5df15":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d6eeb10cdc4f4a56b80534fce9b56098","placeholder":"​","style":"IPY_MODEL_3507b6cff9bb4ab18c13131ae27aa344","value":" 53/53 [00:05&lt;00:00, 18.72it/s]"}},"628937f54b934e00b568bc8acfc947b4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"730153ebc5ce4bf7b709ccdd7f6b67e8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4cdfb5834ee543658da77a1c8c015256":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4820da4c61d3402fb4487bc3f10fea55":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ba59a934aa1d4bbfb60a644d7c8fb7e3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d6eeb10cdc4f4a56b80534fce9b56098":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3507b6cff9bb4ab18c13131ae27aa344":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c499f1a84eb34691884c1863e657f0cb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7ff3298210ba4e62bc162788b86256e9","IPY_MODEL_5d4ceb0f7d8e43d98a24cc839bb8e3fd","IPY_MODEL_b1cb9b150b9441bda6e3248aacdcb819"],"layout":"IPY_MODEL_e383a316673141e2ba29a5299b606957"}},"7ff3298210ba4e62bc162788b86256e9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5a4d524f3d6d4d129ea9f9612c11fb9c","placeholder":"​","style":"IPY_MODEL_44b8ea01b3bc491eb6e04ee3a206ae77","value":"100%"}},"5d4ceb0f7d8e43d98a24cc839bb8e3fd":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_99e84baf7e084804be1b6449a0fbf18b","max":13,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cb8a31701cd2409a81ac1d01e97f65eb","value":13}},"b1cb9b150b9441bda6e3248aacdcb819":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3ca94c248e2d4764bd5e03a5547950f7","placeholder":"​","style":"IPY_MODEL_99551ff9b3f64e3a9ba013b345354a60","value":" 13/13 [00:00&lt;00:00, 11.14it/s]"}},"e383a316673141e2ba29a5299b606957":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5a4d524f3d6d4d129ea9f9612c11fb9c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"44b8ea01b3bc491eb6e04ee3a206ae77":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"99e84baf7e084804be1b6449a0fbf18b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cb8a31701cd2409a81ac1d01e97f65eb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3ca94c248e2d4764bd5e03a5547950f7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"99551ff9b3f64e3a9ba013b345354a60":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W5h9VbyP5RUP","executionInfo":{"status":"ok","timestamp":1721642787753,"user_tz":-330,"elapsed":84276,"user":{"displayName":"Anurag Satbhai","userId":"11722695677150668725"}},"outputId":"b48e3ca4-7839-4481-8f1d-e39a1e534177"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting ultralytics\n","  Downloading ultralytics-8.2.62-py3-none-any.whl (825 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/825.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.9/825.2 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m819.2/825.2 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m825.2/825.2 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy<2.0.0,>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.25.2)\n","Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n","Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.8.0.76)\n","Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.4.0)\n","Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.1)\n","Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.31.0)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.11.4)\n","Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.3.1+cu121)\n","Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.18.1+cu121)\n","Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.4)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n","Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n","Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.0.3)\n","Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.1)\n","Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n","  Downloading ultralytics_thop-2.0.0-py3-none-any.whl (25 kB)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.2.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.53.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.1)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.2)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2023.4)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.7.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.15.4)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2023.6.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.8.0->ultralytics)\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.8.0->ultralytics)\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.8.0->ultralytics)\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.8.0->ultralytics)\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.8.0->ultralytics)\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.8.0->ultralytics)\n","  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.8.0->ultralytics)\n","  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n","  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2.3.1)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.0->ultralytics)\n","  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m59.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n","Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\n","Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105 ultralytics-8.2.62 ultralytics-thop-2.0.0\n"]}],"source":["# Pip install (recommended)\n","\n","!pip install ultralytics"]},{"cell_type":"code","source":["## importing required libraries\n","import os\n","import shutil\n","import random\n","\n","!pip install tqdm --upgrade\n","from tqdm.notebook import tqdm"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tbZ91i-E5o17","executionInfo":{"status":"ok","timestamp":1721642806714,"user_tz":-330,"elapsed":10180,"user":{"displayName":"Anurag Satbhai","userId":"11722695677150668725"}},"outputId":"d0007d6a-5be2-4128-82f6-f69d894028d6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.4)\n"]}]},{"cell_type":"code","source":["## connecting to the google drive\n","\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-DX4nTNF6ENg","executionInfo":{"status":"ok","timestamp":1721642838136,"user_tz":-330,"elapsed":22269,"user":{"displayName":"Anurag Satbhai","userId":"11722695677150668725"}},"outputId":"efc9301c-1436-464c-a878-508ae39a6016"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["train_path_img = \"./yolo_data/images/train/\"\n","train_path_label = \"./yolo_data/labels/train/\"\n","val_path_img = \"./yolo_data/images/val/\"\n","val_path_label = \"./yolo_data/labels/val/\"\n","test_path = \"./yolo_data/test\""],"metadata":{"id":"UCwUXDid6I2N"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["'''\n","Split the dataset into train and test and creates the train.txt and test.tx with\n","the respective path of the images in each folder\n","'''\n","\n","def train_test_split(path,neg_path=None, split = 0.2):\n","    print(\"------ PROCESS STARTED -------\")\n","\n","\n","    files = list(set([name[:-4] for name in os.listdir(path)])) ## removing duplicate names i.e. counting only number of images\n","\n","\n","    print (f\"--- This folder has a total number of {len(files)} images---\")\n","    random.seed(42)\n","    random.shuffle(files)\n","\n","    test_size = int(len(files) * split)\n","    train_size = len(files) - test_size\n","\n","    ## creating required directories\n","\n","    os.makedirs(train_path_img, exist_ok = True)\n","    os.makedirs(train_path_label, exist_ok = True)\n","    os.makedirs(val_path_img, exist_ok = True)\n","    os.makedirs(val_path_label, exist_ok = True)\n","\n","\n","    ### ----------- copying images to train folder\n","    for filex in tqdm(files[:train_size]):\n","      if filex == 'classes':\n","          continue\n","      shutil.copy2(path + filex + '.jpg',f\"{train_path_img}/\" + filex + '.jpg' )\n","      shutil.copy2(path + filex + '.txt', f\"{train_path_label}/\" + filex + '.txt')\n","\n","\n","\n","    print(f\"------ Training data created with 80% split {len(files[:train_size])} images -------\")\n","\n","    if neg_path:\n","        neg_images = list(set([name[:-4] for name in os.listdir(neg_path)])) ## removing duplicate names i.e. counting only number of images\n","        for filex in tqdm(neg_images):\n","            shutil.copy2(neg_path+filex+ \".jpg\", f\"{train_path_img}/\" + filex + '.jpg')\n","\n","        print(f\"------ Total  {len(neg_images)} negative images added to the training data -------\")\n","\n","        print(f\"------ TOTAL Training data created with {len(files[:train_size]) + len(neg_images)} images -------\")\n","\n","\n","\n","    ### copytin images to validation folder\n","    for filex in tqdm(files[train_size:]):\n","      if filex == 'classes':\n","          continue\n","      # print(\"running\")\n","      shutil.copy2(path + filex + '.jpg', f\"{val_path_img}/\" + filex + '.jpg' )\n","      shutil.copy2(path + filex + '.txt', f\"{val_path_label}/\" + filex + '.txt')\n","\n","    print(f\"------ Testing data created with a total of {len(files[train_size:])} images ----------\")\n","\n","    print(\"------ TASK COMPLETED -------\")\n","\n","## spliting the data into train-test and creating train.txt and test.txt files\n","# train_test_split('/content/drive/MyDrive/custom_notebooks/yolo_data/')\n","\n","### for label_tag\n","train_test_split('/content/drive/MyDrive/yolov8/data/') ### without negative images\n","# train_test_split('./data/','./negative_images/') ### if you want to feed negative images"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":168,"referenced_widgets":["ccac1a1d4fa94d6884d008f891cc1fec","9d59f586961c43fc848940dd906dbc4c","04e785dc9ccc470bb8e6ad077305ab9f","2daa98354c5f41d490e6b217d0b5df15","628937f54b934e00b568bc8acfc947b4","730153ebc5ce4bf7b709ccdd7f6b67e8","4cdfb5834ee543658da77a1c8c015256","4820da4c61d3402fb4487bc3f10fea55","ba59a934aa1d4bbfb60a644d7c8fb7e3","d6eeb10cdc4f4a56b80534fce9b56098","3507b6cff9bb4ab18c13131ae27aa344","c499f1a84eb34691884c1863e657f0cb","7ff3298210ba4e62bc162788b86256e9","5d4ceb0f7d8e43d98a24cc839bb8e3fd","b1cb9b150b9441bda6e3248aacdcb819","e383a316673141e2ba29a5299b606957","5a4d524f3d6d4d129ea9f9612c11fb9c","44b8ea01b3bc491eb6e04ee3a206ae77","99e84baf7e084804be1b6449a0fbf18b","cb8a31701cd2409a81ac1d01e97f65eb","3ca94c248e2d4764bd5e03a5547950f7","99551ff9b3f64e3a9ba013b345354a60"]},"id":"dSE4yedT6Pi-","executionInfo":{"status":"ok","timestamp":1721642900837,"user_tz":-330,"elapsed":6677,"user":{"displayName":"Anurag Satbhai","userId":"11722695677150668725"}},"outputId":"2969da88-6fdc-49ff-fbc4-e4e4ba30f069"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["------ PROCESS STARTED -------\n","--- This folder has a total number of 66 images---\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/53 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ccac1a1d4fa94d6884d008f891cc1fec"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["------ Training data created with 80% split 53 images -------\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/13 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c499f1a84eb34691884c1863e657f0cb"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["------ Testing data created with a total of 13 images ----------\n","------ TASK COMPLETED -------\n"]}]},{"cell_type":"code","source":["import ultralytics\n","ultralytics.checks()"],"metadata":{"id":"E_Yo_9EW6byS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1721643589835,"user_tz":-330,"elapsed":9674,"user":{"displayName":"Anurag Satbhai","userId":"11722695677150668725"}},"outputId":"74fb2be1-9db6-46d3-d817-9c85122c601a"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Ultralytics YOLOv8.2.62 🚀 Python-3.10.12 torch-2.3.1+cu121 CPU (Intel Xeon 2.20GHz)\n","Setup complete ✅ (2 CPUs, 12.7 GB RAM, 30.3/107.7 GB disk)\n"]}]},{"cell_type":"code","source":["!yolo task=detect mode=train model=yolov8s.pt data=/content/drive/MyDrive/yolov8/dataset.yaml epochs=10 imgsz=640 batch=8 project=/content/drive/MyDrive/yolov8/training_results name=football\n",""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"253kSFyj9Dg7","executionInfo":{"status":"ok","timestamp":1721645137562,"user_tz":-330,"elapsed":1479618,"user":{"displayName":"Anurag Satbhai","userId":"11722695677150668725"}},"outputId":"c5a8d61c-7a1d-4f04-cbbf-1d835b1e1eb8"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8s.pt to 'yolov8s.pt'...\n","100% 21.5M/21.5M [00:00<00:00, 151MB/s] \n","Ultralytics YOLOv8.2.62 🚀 Python-3.10.12 torch-2.3.1+cu121 CPU (Intel Xeon 2.20GHz)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8s.pt, data=/content/drive/MyDrive/yolov8/dataset.yaml, epochs=10, time=None, patience=100, batch=8, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=/content/drive/MyDrive/yolov8/training_results, name=football, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/content/drive/MyDrive/yolov8/training_results/football\n","Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n","100% 755k/755k [00:00<00:00, 7.93MB/s]\n","Overriding model.yaml nc=80 with nc=2\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n","  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n","  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n","  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n","  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n","  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n"," 22        [15, 18, 21]  1   2116822  ultralytics.nn.modules.head.Detect           [2, [128, 256, 512]]          \n","Model summary: 225 layers, 11,136,374 parameters, 11,136,358 gradients, 28.6 GFLOPs\n","\n","Transferred 349/355 items from pretrained weights\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /content/drive/MyDrive/yolov8/training_results/football', view at http://localhost:6006/\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/yolo_data/labels/train... 53 images, 0 backgrounds, 0 corrupt: 100% 53/53 [00:00<00:00, 898.21it/s]\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/yolo_data/labels/train.cache\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/yolo_data/labels/val... 13 images, 0 backgrounds, 0 corrupt: 100% 13/13 [00:00<00:00, 1561.27it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/yolo_data/labels/val.cache\n","Plotting labels to /content/drive/MyDrive/yolov8/training_results/football/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n","Image sizes 640 train, 640 val\n","Using 0 dataloader workers\n","Logging results to \u001b[1m/content/drive/MyDrive/yolov8/training_results/football\u001b[0m\n","Starting training for 10 epochs...\n","Closing dataloader mosaic\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       1/10         0G      1.764      1.615      1.165         51        640: 100% 7/7 [02:30<00:00, 21.45s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:07<00:00,  7.48s/it]\n","                   all         13        146       0.95       0.47      0.464      0.249\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       2/10         0G      1.484     0.9636       1.03         56        640: 100% 7/7 [02:10<00:00, 18.61s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:08<00:00,  8.97s/it]\n","                   all         13        146      0.964      0.481      0.592       0.29\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       3/10         0G      1.427     0.9088     0.9772         52        640: 100% 7/7 [02:09<00:00, 18.46s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:06<00:00,  6.70s/it]\n","                   all         13        146      0.751      0.738      0.762      0.338\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       4/10         0G      1.452     0.8351      1.021         53        640: 100% 7/7 [02:11<00:00, 18.75s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:07<00:00,  7.54s/it]\n","                   all         13        146      0.308      0.796      0.328      0.162\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       5/10         0G      1.404     0.7896      1.002         53        640: 100% 7/7 [02:10<00:00, 18.59s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:11<00:00, 11.88s/it]\n","                   all         13        146      0.477      0.633      0.538      0.293\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       6/10         0G      1.398     0.7793     0.9864         59        640: 100% 7/7 [02:10<00:00, 18.61s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:07<00:00,  7.89s/it]\n","                   all         13        146      0.458      0.693      0.545      0.282\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       7/10         0G      1.413     0.7703     0.9838         57        640: 100% 7/7 [02:12<00:00, 18.87s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:06<00:00,  6.82s/it]\n","                   all         13        146      0.511      0.724      0.579      0.291\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       8/10         0G      1.338     0.7225     0.9462         42        640: 100% 7/7 [02:09<00:00, 18.45s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:08<00:00,  8.91s/it]\n","                   all         13        146      0.901      0.769        0.8      0.394\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       9/10         0G      1.337     0.7176     0.9989         30        640: 100% 7/7 [02:09<00:00, 18.53s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:06<00:00,  6.93s/it]\n","                   all         13        146      0.915      0.762      0.798      0.406\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      10/10         0G      1.303     0.6512     0.9609         62        640: 100% 7/7 [02:15<00:00, 19.38s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:06<00:00,  6.98s/it]\n","                   all         13        146      0.922      0.765      0.794      0.412\n","\n","10 epochs completed in 0.398 hours.\n","Optimizer stripped from /content/drive/MyDrive/yolov8/training_results/football/weights/last.pt, 22.5MB\n","Optimizer stripped from /content/drive/MyDrive/yolov8/training_results/football/weights/best.pt, 22.5MB\n","\n","Validating /content/drive/MyDrive/yolov8/training_results/football/weights/best.pt...\n","Ultralytics YOLOv8.2.62 🚀 Python-3.10.12 torch-2.3.1+cu121 CPU (Intel Xeon 2.20GHz)\n","Model summary (fused): 168 layers, 11,126,358 parameters, 0 gradients, 28.4 GFLOPs\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:08<00:00,  8.73s/it]\n","                   all         13        146      0.923      0.765      0.794      0.411\n","                player         13        135       0.85      0.985      0.986      0.576\n","              football         11         11      0.996      0.545      0.602      0.246\n","Speed: 1.3ms preprocess, 479.4ms inference, 0.0ms loss, 1.3ms postprocess per image\n","Results saved to \u001b[1m/content/drive/MyDrive/yolov8/training_results/football\u001b[0m\n","💡 Learn more at https://docs.ultralytics.com/modes/train\n"]}]},{"cell_type":"code","source":["!yolo task=detect mode=predict model=/content/drive/MyDrive/yolov8/training_results/football/weights/best.pt conf=0.55 source=/content/drive/MyDrive/yolov8/test_images\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RZiX6Cni9WQs","executionInfo":{"status":"ok","timestamp":1721645589988,"user_tz":-330,"elapsed":15644,"user":{"displayName":"Anurag Satbhai","userId":"11722695677150668725"}},"outputId":"35f6ef67-8e61-4282-8dd4-c1f578676e26"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Ultralytics YOLOv8.2.62 🚀 Python-3.10.12 torch-2.3.1+cu121 CPU (Intel Xeon 2.20GHz)\n","Model summary (fused): 168 layers, 11,126,358 parameters, 0 gradients, 28.4 GFLOPs\n","\n","image 1/9 /content/drive/MyDrive/yolov8/test_images/Copy of 22d_f_120_6ty.jpg: 384x640 12 players, 1 football, 406.7ms\n","image 2/9 /content/drive/MyDrive/yolov8/test_images/Copy of 22d_f_125.jpg: 384x640 6 players, 364.4ms\n","image 3/9 /content/drive/MyDrive/yolov8/test_images/Copy of 22d_f_125_fre.jpg: 384x640 12 players, 379.7ms\n","image 4/9 /content/drive/MyDrive/yolov8/test_images/Copy of 22d_f_55_22d.jpg: 384x640 11 players, 388.4ms\n","image 5/9 /content/drive/MyDrive/yolov8/test_images/Copy of 22d_f_80.jpg: 384x640 7 players, 595.8ms\n","image 6/9 /content/drive/MyDrive/yolov8/test_images/Copy of 22d_f_85_fr.jpg: 384x640 11 players, 587.6ms\n","image 7/9 /content/drive/MyDrive/yolov8/test_images/Copy of 54r_f_120.jpg: 384x640 5 players, 603.3ms\n","image 8/9 /content/drive/MyDrive/yolov8/test_images/Copy of 54r_f_5_22d.jpg: 384x640 13 players, 1 football, 625.9ms\n","image 9/9 /content/drive/MyDrive/yolov8/test_images/Copy of 54r_f_75_we.jpg: 384x640 12 players, 1 football, 385.4ms\n","Speed: 3.7ms preprocess, 481.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","Results saved to \u001b[1mruns/detect/predict2\u001b[0m\n","💡 Learn more at https://docs.ultralytics.com/modes/predict\n"]}]},{"cell_type":"code","source":["!cp -r /content/runs/detect/predict2 /content/drive/MyDrive/yolov8/output"],"metadata":{"id":"C6VrxMzQDOhl","executionInfo":{"status":"ok","timestamp":1721645703842,"user_tz":-330,"elapsed":713,"user":{"displayName":"Anurag Satbhai","userId":"11722695677150668725"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"qHBlIHcKFJ0y"},"execution_count":null,"outputs":[]}]}